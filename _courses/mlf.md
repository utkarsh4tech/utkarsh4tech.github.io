---
layout: page
title: Machine Learning Foundations
description: "A foundational course covering the essential mathematical prerequisites—Calculus, Linear Algebra, Optimization, and Probability—necessary for a comprehensive understanding of Machine Learning."
img: assets/img/mlf.jpg
importance: 1
category: "Data Science"
---

This course built the solid mathematical and statistical bedrock upon which modern machine learning is built. It was designed to provide a comprehensive understanding of the core concepts that underpin ML algorithms. We delved deep into the essential pillars: linear algebra for data representation and dimensionality reduction (Eigenvectors, SVD, PCA); calculus and optimization theory for training models (unconstrained and constrained optimization, Lagrange multipliers); and probability for modeling uncertainty (probabilistic models, exponential family, and the Expectation-Maximization algorithm). This course provided the "why" behind the "how" of machine learning.

---

## Instructors

- [Prof. Harish Guruprasad Ramaswamy](https://www.cse.iitm.ac.in/profile.php?arg=MTgzNA==), Department of Computer Science & Engineering, IIT Madras
- [Prof. Arun Rajkumar](https://www.cse.iitm.ac.in/profile.php?arg=MjA0MA==), Department of Computer Science & Engineering, IIT Madras
- [Prof. Prashanth L.A.](https://www.cse.iitm.ac.in/~prashla/), Department of Computer Science & Engineering, IIT Madras

---

## Course Schedule & Topics

The course is structured over 12 weeks, focusing on the mathematical and statistical fundamentals of machine learning.

| Week   | Primary Focus                       | Key Topics Covered                                                                            |
| :----- | :---------------------------------- | :-------------------------------------------------------------------------------------------- |
| **1**  | Introduction to Machine Learning    | An overview of the field and the role of foundational mathematics.                            |
| **2**  | Review of Calculus                  | Essential calculus concepts required for optimization in machine learning.                    |
| **3**  | Linear Algebra: Least Squares       | Using linear algebra to solve Least Squares Regression problems.                              |
| **4**  | Linear Algebra: Eigen-decomposition | Understanding eigenvalues and eigenvectors.                                                   |
| **5**  | Linear Algebra: Symmetric Matrices  | Special properties and applications of symmetric matrices.                                    |
| **6**  | Linear Algebra: SVD & PCA           | Singular Value Decomposition (SVD) and its application in Principal Component Analysis (PCA). |
| **7**  | Unconstrained Optimization          | Techniques for solving optimization problems without constraints.                             |
| **8**  | Convex Optimization                 | Fundamentals of convex sets, functions, and optimization problems.                            |
| **9**  | Constrained Optimization            | Lagrange Multipliers and framing Logistic Regression as an optimization problem.              |
| **10** | Probabilistic Models in ML          | Examples of probabilistic models and their use in machine learning.                           |
| **11** | Exponential Family of Distributions | Understanding the exponential family and its importance in generalized linear models.         |
| **12** | Parameter Estimation & EM           | Methods for parameter estimation, including the Expectation-Maximization (EM) algorithm.      |

---

## Material used

- [`Mathematics for Machine Learning`](https://mml-book.github.io/book/mml-book.pdf) by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong
